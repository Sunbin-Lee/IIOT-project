{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eae2ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "df_1 = pd.read_csv('normal_vec.csv', header=None)\n",
    "df_2 = pd.read_csv('abnormal_vec.csv', header=None)\n",
    "df_3 = pd.read_csv('error_vec.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7335fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def normal_make_instance(df):\n",
    "    scaler = StandardScaler()\n",
    "    noise = np.random.normal(0, 7, (15,6))\n",
    "    list_scaled = scaler.fit_transform(df + noise)\n",
    "    abc = np.concatenate((np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]]),list_scaled,np.array([[0,0,0,0,0,0],[0,0,0,0,0,0]])))\n",
    "    b = torch.from_numpy(abc)\n",
    "    instance = [b, 0]\n",
    "    return instance\n",
    "\n",
    "def abnormal_make_instance(df):\n",
    "    scaler = StandardScaler()\n",
    "    noise = np.random.normal(0, 7, (19,6))\n",
    "    list_scaled = scaler.fit_transform(df + noise)\n",
    "    abc = np.concatenate((list_scaled, np.array([[0,0,0,0,0,0]])))\n",
    "    b = torch.from_numpy(abc) \n",
    "    instance = [b, 1]\n",
    "    return instance\n",
    "\n",
    "def error_make_instance(df):\n",
    "    scaler = StandardScaler()\n",
    "    noise = np.random.normal(0, 7, (20,6))\n",
    "    list_scaled = scaler.fit_transform(df + noise)\n",
    "    b = torch.from_numpy(list_scaled)\n",
    "    instance = [b, 2]\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c268f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(df_nor, df_ab, df_er, num):\n",
    "    dataset = []\n",
    "    for i in range(num):\n",
    "        dataset.append(normal_make_instance(df_nor))\n",
    "        dataset.append(abnormal_make_instance(df_ab))\n",
    "        dataset.append(error_make_instance(df_er))\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fd00a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = make_ds(df_1, df_2, df_3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1b323995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 9465  4990 23348 ...  8551  7658 23236] test: [28621 18384 29068 ... 29031 11744 16112]\n",
      "24000 6000\n",
      "train: [20242 12026  6805 ... 21690 23550 22921] val: [ 6628  2421  8359 ... 20429 12307 18328]\n",
      "18000 6000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = random_seed)\n",
    "indices = list(range(len(total_dataset)))\n",
    "y_ds = [y for _, y in total_dataset]\n",
    "\n",
    "for train_index, test_index in sss.split(indices, y_ds):\n",
    "    print('train:', train_index, 'test:', test_index)\n",
    "    print(len(train_index), len(test_index))\n",
    "\n",
    "sub_train = Subset(total_dataset, train_index)\n",
    "test_ds = Subset(total_dataset, test_index)\n",
    "\n",
    "sss2 = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = random_seed)\n",
    "indices2 = list(range(len(sub_train)))\n",
    "y_ds2 = [y for _, y in sub_train]\n",
    "\n",
    "for train_index2, val_index in sss2.split(indices2, y_ds2):\n",
    "    print('train:', train_index2, 'val:', val_index)\n",
    "    print(len(train_index2), len(val_index))\n",
    "\n",
    "train_ds = Subset(sub_train, train_index2)\n",
    "val_ds = Subset(sub_train, val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f8607c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 6])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_ds[0]\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "617375eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size= batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size= batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size= batch_size, shuffle=False, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f346b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=3, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # setup LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # setup output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        # lstm step => then ONLY take the sequence's final timetep to pass into the linear/dense layer\n",
    "        # Note: lstm_out contains outputs for every step of the sequence we are looping over (for BPTT)\n",
    "        # but we just need the output of the last step of the sequence, aka lstm_out[-1]\n",
    "        lstm_out, hidden = self.lstm(input, hidden)\n",
    "        logits = self.linear(lstm_out[-1])              # equivalent to return_sequences=False from Keras\n",
    "        #softmax = F.softmax(logits)\n",
    "\n",
    "        return logits, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "55498d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = LSTM(input_dim = 6, hidden_dim = 3, output_dim = 3, num_layers = 1).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "#lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=20, min_lr=1e-6, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4dea310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def Accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8da203c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 , train_loss : 1.1955670487414052, train_acc : 33.68549822064057, val_loss : 1.1867542997483285, val_acc : 34.038978494623656 \n",
      "Epoch : 1 , train_loss : 1.178147371129209, train_acc : 34.224866548042705, val_loss : 1.168733089200912, val_acc : 34.81182795698925 \n",
      "Epoch : 2 , train_loss : 1.1589972620757025, train_acc : 35.94306049822064, val_loss : 1.1475175093579035, val_acc : 38.894489247311824 \n",
      "Epoch : 3 , train_loss : 1.1336849427308051, train_acc : 44.82317615658363, val_loss : 1.1166184147198994, val_acc : 51.276881720430104 \n",
      "Epoch : 4 , train_loss : 1.0958537011808347, train_acc : 55.64946619217082, val_loss : 1.0704655217868027, val_acc : 58.31653225806452 \n",
      "Epoch : 5 , train_loss : 1.0394567327567268, train_acc : 60.220195729537366, val_loss : 1.0065578722184705, val_acc : 61.87836021505376 \n",
      "Epoch : 6 , train_loss : 0.9759421921285446, train_acc : 63.42304270462633, val_loss : 0.9443369648789847, val_acc : 64.53293010752688 \n",
      "Epoch : 7 , train_loss : 0.9153545880657074, train_acc : 65.26356761565836, val_loss : 0.8854397919870192, val_acc : 65.60819892473118 \n",
      "Epoch : 8 , train_loss : 0.8583636983857884, train_acc : 66.05315836298932, val_loss : 0.8308357936079784, val_acc : 66.07862903225806 \n",
      "Epoch : 9 , train_loss : 0.8068204780914605, train_acc : 66.35342526690391, val_loss : 0.7830360679216283, val_acc : 66.34744623655914 \n",
      "Epoch : 10 , train_loss : 0.7627215088474368, train_acc : 66.45351423487544, val_loss : 0.7436058578952667, val_acc : 66.39784946236558 \n",
      "Epoch : 11 , train_loss : 0.7258549302922449, train_acc : 66.49243772241992, val_loss : 0.7111584454454402, val_acc : 66.34744623655914 \n",
      "Epoch : 12 , train_loss : 0.6947883855405651, train_acc : 66.52580071174377, val_loss : 0.6830480335861124, val_acc : 66.39784946236558 \n",
      "Epoch : 13 , train_loss : 0.6682882695011397, train_acc : 66.52024021352314, val_loss : 0.6610558173989737, val_acc : 66.48185483870968 \n",
      "Epoch : 14 , train_loss : 0.6454342909130761, train_acc : 66.53692170818505, val_loss : 0.6409172018369039, val_acc : 66.46505376344086 \n",
      "Epoch : 15 , train_loss : 0.625685031727964, train_acc : 66.5424822064057, val_loss : 0.6265365865922743, val_acc : 66.38104838709677 \n",
      "Epoch : 16 , train_loss : 0.6086227227784561, train_acc : 66.55916370106762, val_loss : 0.61490229188755, val_acc : 66.33064516129032 \n",
      "Epoch : 17 , train_loss : 0.5933361156343141, train_acc : 66.65925266903915, val_loss : 0.6051703633800629, val_acc : 66.44825268817205 \n",
      "Epoch : 18 , train_loss : 0.5798407979707276, train_acc : 68.20507117437722, val_loss : 0.602814729495715, val_acc : 70.73252688172043 \n",
      "Epoch : 19 , train_loss : 0.5679989827273155, train_acc : 77.89145907473309, val_loss : 0.6057142955000683, val_acc : 77.80577956989248 \n",
      "Epoch : 20 , train_loss : 0.5574241187224609, train_acc : 76.82384341637011, val_loss : 0.6131192221436449, val_acc : 70.56451612903226 \n",
      "Epoch : 21 , train_loss : 0.5481260854790644, train_acc : 71.17437722419929, val_loss : 0.6249498225027516, val_acc : 64.70094086021506 \n",
      "Epoch : 22 , train_loss : 0.5395262963619096, train_acc : 67.90480427046263, val_loss : 0.6392258572322066, val_acc : 63.32325268817204 \n",
      "Epoch : 23 , train_loss : 0.532049702791981, train_acc : 68.54982206405694, val_loss : 0.6528904149609227, val_acc : 61.340725806451616 \n",
      "Epoch : 24 , train_loss : 0.5251867660848272, train_acc : 68.39968861209964, val_loss : 0.6667285862789359, val_acc : 60.601478494623656 \n",
      "Epoch : 25 , train_loss : 0.5189459969776805, train_acc : 68.7221975088968, val_loss : 0.6914684343081648, val_acc : 59.509408602150536 \n",
      "Epoch : 26 , train_loss : 0.5130540379637926, train_acc : 68.63322953736655, val_loss : 0.7006065063579108, val_acc : 59.19018817204301 \n",
      "Epoch : 27 , train_loss : 0.5075893639669724, train_acc : 70.01779359430606, val_loss : 0.7143622335567269, val_acc : 59.81182795698925 \n",
      "Epoch : 28 , train_loss : 0.5023028087997776, train_acc : 70.65725088967972, val_loss : 0.7291215568460444, val_acc : 60.803091397849464 \n",
      "Epoch : 29 , train_loss : 0.4970302271036915, train_acc : 76.07873665480427, val_loss : 0.7367155734569796, val_acc : 63.776881720430104 \n",
      "Epoch : 30 , train_loss : 0.49160761638044037, train_acc : 79.0702846975089, val_loss : 0.7559719258739103, val_acc : 67.0866935483871 \n",
      "Epoch : 31 , train_loss : 0.4860191766265448, train_acc : 84.56405693950178, val_loss : 0.7388967480710757, val_acc : 73.48790322580645 \n",
      "Epoch : 32 , train_loss : 0.4798991615449831, train_acc : 88.84564056939502, val_loss : 0.7359635714561709, val_acc : 79.85551075268818 \n",
      "Epoch : 33 , train_loss : 0.4732134170379503, train_acc : 94.817615658363, val_loss : 0.7414967190193874, val_acc : 81.7372311827957 \n",
      "Epoch : 34 , train_loss : 0.46573016015660296, train_acc : 95.52935943060498, val_loss : 0.7259850008513338, val_acc : 82.15725806451613 \n",
      "Epoch : 35 , train_loss : 0.4574922282924856, train_acc : 95.59052491103203, val_loss : 0.7249373226396499, val_acc : 82.00604838709677 \n",
      "Epoch : 36 , train_loss : 0.44809230122701976, train_acc : 95.59608540925267, val_loss : 0.7158351761679496, val_acc : 81.88844086021506 \n",
      "Epoch : 37 , train_loss : 0.4379682337262028, train_acc : 95.29025800711744, val_loss : 0.7222071017629357, val_acc : 81.80443548387096 \n",
      "Epoch : 38 , train_loss : 0.42730916426699356, train_acc : 95.25133451957295, val_loss : 0.7090230894986019, val_acc : 82.10685483870968 \n",
      "Epoch : 39 , train_loss : 0.4160032636118105, train_acc : 95.06227758007117, val_loss : 0.6840212386782452, val_acc : 82.77889784946237 \n",
      "Epoch : 40 , train_loss : 0.40444413697168075, train_acc : 95.17904804270462, val_loss : 0.6910008518926559, val_acc : 82.44287634408602 \n",
      "Epoch : 41 , train_loss : 0.39285039127509364, train_acc : 95.34586298932385, val_loss : 0.6796082171701616, val_acc : 82.7116935483871 \n",
      "Epoch : 42 , train_loss : 0.38129070358768474, train_acc : 95.37922597864768, val_loss : 0.6674088579352184, val_acc : 83.06451612903226 \n",
      "Epoch : 43 , train_loss : 0.3699231921990147, train_acc : 95.38478647686833, val_loss : 0.6696381681067969, val_acc : 82.8125 \n",
      "Epoch : 44 , train_loss : 0.35866312189458527, train_acc : 95.42370996441281, val_loss : 0.6888455017920463, val_acc : 82.15725806451613 \n",
      "Epoch : 45 , train_loss : 0.34790188890759205, train_acc : 95.50711743772241, val_loss : 0.6690798161491271, val_acc : 82.96370967741936 \n",
      "Epoch : 46 , train_loss : 0.3373886392421994, train_acc : 95.58496441281139, val_loss : 0.6714184700801809, val_acc : 82.84610215053763 \n",
      "Epoch : 47 , train_loss : 0.32730002547498277, train_acc : 95.62388790035587, val_loss : 0.6917017483583061, val_acc : 81.97244623655914 \n",
      "Epoch : 48 , train_loss : 0.3175613552968273, train_acc : 95.70173487544484, val_loss : 0.6874052061829515, val_acc : 82.20766129032258 \n",
      "Epoch : 49 , train_loss : 0.3079061619539702, train_acc : 95.7517793594306, val_loss : 0.7185719455442121, val_acc : 81.03158602150538 \n",
      "Epoch : 50 , train_loss : 0.29888644194051467, train_acc : 95.86298932384342, val_loss : 0.7231568601182712, val_acc : 80.98118279569893 \n",
      "Epoch : 51 , train_loss : 0.28997424987287285, train_acc : 95.85186832740213, val_loss : 0.7234418177476494, val_acc : 80.96438172043011 \n",
      "Epoch : 52 , train_loss : 0.2814231537733214, train_acc : 95.97419928825623, val_loss : 0.7537264662083759, val_acc : 80.09072580645162 \n",
      "Epoch : 53 , train_loss : 0.27299267127844784, train_acc : 96.01868327402136, val_loss : 0.7415382761147714, val_acc : 80.46034946236558 \n",
      "Epoch : 54 , train_loss : 0.26476410301766784, train_acc : 96.07428825622776, val_loss : 0.7690333169634624, val_acc : 79.5866935483871 \n",
      "Epoch : 55 , train_loss : 0.2569130782130774, train_acc : 96.14657473309609, val_loss : 0.7843731151473138, val_acc : 78.94825268817205 \n",
      "Epoch : 56 , train_loss : 0.24911440177108046, train_acc : 96.21886120996442, val_loss : 0.812314808689138, val_acc : 78.25940860215054 \n",
      "Epoch : 57 , train_loss : 0.24131484653177634, train_acc : 96.28002669039147, val_loss : 0.7892718558670372, val_acc : 78.89784946236558 \n",
      "Epoch : 58 , train_loss : 0.2335002691720304, train_acc : 96.35787366548043, val_loss : 0.78079401132881, val_acc : 78.93145161290323 \n",
      "Epoch : 59 , train_loss : 0.2259030433842296, train_acc : 96.4357206405694, val_loss : 0.768874702754841, val_acc : 79.41868279569893 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 60 , train_loss : 0.217965764348193, train_acc : 96.48576512455516, val_loss : 0.7530316085584702, val_acc : 79.56989247311827 \n",
      "Epoch : 61 , train_loss : 0.20999951740176653, train_acc : 96.53580960854093, val_loss : 0.7606489031866033, val_acc : 79.48588709677419 \n",
      "Epoch : 62 , train_loss : 0.2018393055399966, train_acc : 96.64145907473309, val_loss : 0.7299118714947854, val_acc : 79.93951612903226 \n",
      "Epoch : 63 , train_loss : 0.19393002639567725, train_acc : 96.68594306049822, val_loss : 0.718964286869572, val_acc : 80.27553763440861 \n",
      "Epoch : 64 , train_loss : 0.18605134882748764, train_acc : 96.76379003558719, val_loss : 0.7132396598656973, val_acc : 80.72916666666667 \n",
      "Epoch : 65 , train_loss : 0.17837276431695423, train_acc : 96.83607651245552, val_loss : 0.7017685258260338, val_acc : 80.49395161290323 \n",
      "Epoch : 66 , train_loss : 0.17089813992752298, train_acc : 96.89724199288256, val_loss : 0.7102087386833724, val_acc : 80.10752688172043 \n",
      "Epoch : 67 , train_loss : 0.16390434827562753, train_acc : 96.9306049822064, val_loss : 0.6816566628153606, val_acc : 80.91397849462365 \n",
      "Epoch : 68 , train_loss : 0.1573334565101145, train_acc : 97.01957295373666, val_loss : 0.6777421223220005, val_acc : 80.8635752688172 \n",
      "Epoch : 69 , train_loss : 0.15104667274977387, train_acc : 97.14746441281139, val_loss : 0.6780061010391482, val_acc : 80.82997311827957 \n",
      "Epoch : 70 , train_loss : 0.14521260175098305, train_acc : 97.16970640569394, val_loss : 0.6592159841650276, val_acc : 81.78763440860214 \n",
      "Epoch : 71 , train_loss : 0.13964287432911557, train_acc : 97.2586743772242, val_loss : 0.6633751168045946, val_acc : 81.65322580645162 \n",
      "Epoch : 72 , train_loss : 0.13463171444223446, train_acc : 97.31983985765125, val_loss : 0.6377620713044239, val_acc : 82.14045698924731 \n",
      "Epoch : 73 , train_loss : 0.12989693307367509, train_acc : 97.45329181494662, val_loss : 0.6205448167779113, val_acc : 82.64448924731182 \n",
      "Epoch : 74 , train_loss : 0.12542932737764514, train_acc : 97.50333629893238, val_loss : 0.615100250769687, val_acc : 82.54368279569893 \n",
      "Epoch : 75 , train_loss : 0.12117467542241901, train_acc : 97.60342526690391, val_loss : 0.5961613211260047, val_acc : 83.5013440860215 \n",
      "Epoch : 76 , train_loss : 0.11726338816707245, train_acc : 97.64790925266904, val_loss : 0.5964849208311368, val_acc : 83.08131720430107 \n",
      "Epoch : 77 , train_loss : 0.11364571702437892, train_acc : 97.69239323843416, val_loss : 0.5879521164842831, val_acc : 83.43413978494624 \n",
      "Epoch : 78 , train_loss : 0.11017702022746365, train_acc : 97.74799822064057, val_loss : 0.5792175308671049, val_acc : 83.43413978494624 \n",
      "Epoch : 79 , train_loss : 0.10704690325355615, train_acc : 97.79804270462634, val_loss : 0.5781536933074716, val_acc : 83.6861559139785 \n",
      "Epoch : 80 , train_loss : 0.10403648285307918, train_acc : 97.8480871886121, val_loss : 0.5428997293435117, val_acc : 84.87903225806451 \n",
      "Epoch : 81 , train_loss : 0.10119455309047817, train_acc : 97.88145017793595, val_loss : 0.5629039730436058, val_acc : 84.12298387096774 \n",
      "Epoch : 82 , train_loss : 0.09836290583173575, train_acc : 97.92037366548043, val_loss : 0.5236436351332613, val_acc : 85.13104838709677 \n",
      "Epoch : 83 , train_loss : 0.09601941215557136, train_acc : 97.942615658363, val_loss : 0.5527334818115799, val_acc : 84.61021505376344 \n",
      "Epoch : 84 , train_loss : 0.09347025574155125, train_acc : 97.95373665480427, val_loss : 0.552078409460924, val_acc : 84.62701612903226 \n",
      "Epoch : 85 , train_loss : 0.09136113832005402, train_acc : 98.02046263345196, val_loss : 0.5348201358831057, val_acc : 85.18145161290323 \n",
      "Epoch : 86 , train_loss : 0.08924202725715484, train_acc : 98.0260231316726, val_loss : 0.5185229030828322, val_acc : 85.26545698924731 \n",
      "Epoch : 87 , train_loss : 0.08722331251591126, train_acc : 98.07050711743773, val_loss : 0.5155275823368181, val_acc : 85.56787634408602 \n",
      "Epoch : 88 , train_loss : 0.08516980358979456, train_acc : 98.11499110320284, val_loss : 0.5386482933035461, val_acc : 84.91263440860214 \n",
      "Epoch : 89 , train_loss : 0.08345569580713837, train_acc : 98.12611209964413, val_loss : 0.5160779762332157, val_acc : 85.78629032258064 \n",
      "Epoch : 90 , train_loss : 0.08168735691873204, train_acc : 98.15947508896797, val_loss : 0.5199366908480403, val_acc : 85.58467741935483 \n",
      "Epoch : 91 , train_loss : 0.07992308548389805, train_acc : 98.20395907473309, val_loss : 0.5151010367979285, val_acc : 85.92069892473118 \n",
      "Epoch : 92 , train_loss : 0.0784044443460652, train_acc : 98.21508007117438, val_loss : 0.5174064007337376, val_acc : 85.90389784946237 \n",
      "Epoch : 93 , train_loss : 0.0768652868546625, train_acc : 98.24288256227759, val_loss : 0.5034638036002395, val_acc : 86.02150537634408 \n",
      "Epoch : 94 , train_loss : 0.0753037918597672, train_acc : 98.27624555160142, val_loss : 0.5094247763195345, val_acc : 86.20631720430107 \n",
      "Epoch : 95 , train_loss : 0.07391590121934634, train_acc : 98.28180604982207, val_loss : 0.5058889493586556, val_acc : 86.34072580645162 \n",
      "Epoch : 96 , train_loss : 0.07252510914121658, train_acc : 98.30960854092527, val_loss : 0.5108610867492615, val_acc : 86.35752688172043 \n",
      "Epoch : 97 , train_loss : 0.0710312781782549, train_acc : 98.32072953736655, val_loss : 0.47047402076823736, val_acc : 86.8111559139785 \n",
      "Epoch : 98 , train_loss : 0.06994628902272822, train_acc : 98.37077402135232, val_loss : 0.47996593410930327, val_acc : 86.6263440860215 \n",
      "Epoch : 99 , train_loss : 0.06870757653195662, train_acc : 98.39857651245552, val_loss : 0.5086551034642804, val_acc : 86.35752688172043 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    hidden_state = None\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = AverageMeter()\n",
    "    train_accs = AverageMeter()\n",
    "    for idx, (images, target) in enumerate(train_loader):\n",
    "        #print(images.shape)\n",
    "        images = images.permute(1,0,2).cuda()\n",
    "        target = target.cuda()\n",
    "        images = images.type(torch.cuda.FloatTensor)\n",
    "        y_pred, hidden_state = model(images, hidden_state)\n",
    "        #print(\"y_pred\",y_pred)\n",
    "\n",
    "        stateful = False\n",
    "        if not stateful:\n",
    "            hidden_state = None\n",
    "        else:\n",
    "            h_0, c_0 = hidden_state\n",
    "            h_0.detach_(), c_0.detach_()\n",
    "            hidden_state = (h_0, c_0)\n",
    "\n",
    "        train_loss = criterion(y_pred, target)\n",
    "        #print(train_loss)\n",
    "        \n",
    "        train_losses.update(train_loss.item(), images.size(0)) \n",
    "        train_acc = Accuracy(y_pred, target)\n",
    "        train_accs.update(train_acc[0].item(), images.size(0))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        train_loss.backward()  # backward pass\n",
    "        optimizer.step()  # parameter update\n",
    "    #lr_scheduler.step(train_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        hidden_state = None\n",
    "        \n",
    "        val_losses = AverageMeter()\n",
    "        val_accs = AverageMeter()\n",
    "        \n",
    "        for idx, (images, target) in enumerate(val_loader):\n",
    "            images = images.permute(1,0,2).cuda()\n",
    "            target = target.cuda()\n",
    "            images = images.type(torch.cuda.FloatTensor)\n",
    "\n",
    "            y_pred, hidden_state = model(images, hidden_state)\n",
    "            \n",
    "            val_loss = criterion(y_pred, target)\n",
    "            val_losses.update(val_loss.item(), images.size(0)) \n",
    "\n",
    "            val_acc = Accuracy(y_pred, target)\n",
    "            val_accs.update(val_acc[0].item(), images.size(0))\n",
    "            \n",
    "            stateful = True\n",
    "            if not stateful:\n",
    "                hidden_state = None\n",
    "            else:\n",
    "                h_0, c_0 = hidden_state\n",
    "                h_0.detach_(), c_0.detach_()\n",
    "                hidden_state = (h_0, c_0)\n",
    "    \n",
    "    print('Epoch : {} , train_loss : {}, train_acc : {}, val_loss : {}, val_acc : {} '.format(epoch, train_losses.avg, train_accs.avg, val_losses.avg, val_accs.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f7d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6281e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
