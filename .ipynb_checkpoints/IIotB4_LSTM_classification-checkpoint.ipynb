{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae2ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "random_seed = 123\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "df_1 = pd.read_csv('data/normal_vec.csv', header=None)\n",
    "df_2 = pd.read_csv('data/abnormal_vec.csv', header=None)\n",
    "df_3 = pd.read_csv('data/error_vec.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7335fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "def normal_make_instance(df):\n",
    "    scaler = StandardScaler()\n",
    "    noise = np.random.normal(0, 7, (15,6))\n",
    "    list_scaled = scaler.fit_transform(df + noise)\n",
    "    abc = np.concatenate((np.array([[0,0,0,0,0,0],[0,0,0,0,0,0],[0,0,0,0,0,0]]),list_scaled,np.array([[0,0,0,0,0,0],[0,0,0,0,0,0]])))\n",
    "    b = torch.from_numpy(abc)\n",
    "    instance = [b, 0]\n",
    "    return instance\n",
    "\n",
    "def abnormal_make_instance(df):\n",
    "    scaler = StandardScaler()\n",
    "    noise = np.random.normal(0, 7, (19,6))\n",
    "    list_scaled = scaler.fit_transform(df + noise)\n",
    "    abc = np.concatenate((list_scaled, np.array([[0,0,0,0,0,0]])))\n",
    "    b = torch.from_numpy(abc) \n",
    "    instance = [b, 1]\n",
    "    return instance\n",
    "\n",
    "def error_make_instance(df):\n",
    "    scaler = StandardScaler()\n",
    "    noise = np.random.normal(0, 7, (20,6))\n",
    "    list_scaled = scaler.fit_transform(df + noise)\n",
    "    b = torch.from_numpy(list_scaled)\n",
    "    instance = [b, 2]\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c268f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ds(df_nor, df_ab, df_er, num):\n",
    "    dataset = []\n",
    "    for i in range(num):\n",
    "        dataset.append(normal_make_instance(df_nor))\n",
    "        dataset.append(abnormal_make_instance(df_ab))\n",
    "        dataset.append(error_make_instance(df_er))\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd00a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataset = make_ds(df_1, df_2, df_3, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b323995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [ 9465  4990 23348 ...  8551  7658 23236] test: [28621 18384 29068 ... 29031 11744 16112]\n",
      "24000 6000\n",
      "train: [20242 12026  6805 ... 21690 23550 22921] val: [ 6628  2421  8359 ... 20429 12307 18328]\n",
      "18000 6000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2, random_state = random_seed)\n",
    "indices = list(range(len(total_dataset)))\n",
    "y_ds = [y for _, y in total_dataset]\n",
    "\n",
    "for train_index, test_index in sss.split(indices, y_ds):\n",
    "    print('train:', train_index, 'test:', test_index)\n",
    "    print(len(train_index), len(test_index))\n",
    "\n",
    "sub_train = Subset(total_dataset, train_index)\n",
    "test_ds = Subset(total_dataset, test_index)\n",
    "\n",
    "sss2 = StratifiedShuffleSplit(n_splits = 1, test_size = 0.25, random_state = random_seed)\n",
    "indices2 = list(range(len(sub_train)))\n",
    "y_ds2 = [y for _, y in sub_train]\n",
    "\n",
    "for train_index2, val_index in sss2.split(indices2, y_ds2):\n",
    "    print('train:', train_index2, 'val:', val_index)\n",
    "    print(len(train_index2), len(val_index))\n",
    "\n",
    "train_ds = Subset(sub_train, train_index2)\n",
    "val_ds = Subset(sub_train, val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8607c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_ds[0]\n",
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617375eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size= batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size= batch_size, shuffle=True, num_workers=8, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size= batch_size, shuffle=False, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f346b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim=3, num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # setup LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # setup output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        # lstm step => then ONLY take the sequence's final timetep to pass into the linear/dense layer\n",
    "        # Note: lstm_out contains outputs for every step of the sequence we are looping over (for BPTT)\n",
    "        # but we just need the output of the last step of the sequence, aka lstm_out[-1]\n",
    "        lstm_out, hidden = self.lstm(input, hidden)\n",
    "        logits = self.linear(lstm_out[-1])              # equivalent to return_sequences=False from Keras\n",
    "        #softmax = F.softmax(logits)\n",
    "\n",
    "        return logits, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55498d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model = LSTM(input_dim = 6, hidden_dim = 3, output_dim = 3, num_layers = 1).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "#lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=20, min_lr=1e-6, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4dea310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def Accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da203c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 , train_loss : 1.096594584369999, train_acc : 20.857428825622776, val_loss : 1.0877273262187999, val_acc : 22.295026881720432 \n",
      "Epoch : 2 , train_loss : 1.0775833231698575, train_acc : 25.589412811387902, val_loss : 1.0668492547927364, val_acc : 29.637096774193548 \n",
      "Epoch : 3 , train_loss : 1.0542462622992084, train_acc : 39.12922597864769, val_loss : 1.0405162149860012, val_acc : 49.546370967741936 \n",
      "Epoch : 4 , train_loss : 1.0239962657575505, train_acc : 60.55938612099644, val_loss : 1.0062836466297027, val_acc : 69.47244623655914 \n",
      "Epoch : 5 , train_loss : 0.9849368204425663, train_acc : 76.21218861209964, val_loss : 0.962416765510395, val_acc : 80.72916666666667 \n",
      "Epoch : 6 , train_loss : 0.9368616944954489, train_acc : 83.67437722419929, val_loss : 0.9104658628022799, val_acc : 85.41666666666667 \n",
      "Epoch : 7 , train_loss : 0.8808738071723341, train_acc : 86.98843416370107, val_loss : 0.8511446637492026, val_acc : 87.44959677419355 \n",
      "Epoch : 8 , train_loss : 0.8177580010424305, train_acc : 88.90680604982207, val_loss : 0.7853817074529587, val_acc : 89.26411290322581 \n",
      "Epoch : 9 , train_loss : 0.7491049628665014, train_acc : 90.76957295373666, val_loss : 0.7152072409147857, val_acc : 91.34744623655914 \n",
      "Epoch : 10 , train_loss : 0.6792900598346127, train_acc : 92.78247330960853, val_loss : 0.6484747586711761, val_acc : 92.97715053763442 \n",
      "Epoch : 11 , train_loss : 0.6146056128142143, train_acc : 94.37833629893238, val_loss : 0.5892813929947474, val_acc : 94.22043010752688 \n",
      "Epoch : 12 , train_loss : 0.558839368014149, train_acc : 95.47931494661921, val_loss : 0.5392273337610306, val_acc : 95.04368279569893 \n",
      "Epoch : 13 , train_loss : 0.5120901309510567, train_acc : 95.9019128113879, val_loss : 0.4993954662994672, val_acc : 95.26209677419355 \n",
      "Epoch : 14 , train_loss : 0.47319713351565323, train_acc : 96.13545373665481, val_loss : 0.4648857882586859, val_acc : 95.34610215053763 \n",
      "Epoch : 15 , train_loss : 0.4402352250131424, train_acc : 96.20217971530249, val_loss : 0.4344809965420795, val_acc : 95.49731182795699 \n",
      "Epoch : 16 , train_loss : 0.4121858835008221, train_acc : 96.26890569395017, val_loss : 0.4105444595377932, val_acc : 95.51411290322581 \n",
      "Epoch : 17 , train_loss : 0.3876325463697155, train_acc : 96.30782918149467, val_loss : 0.38905960705972487, val_acc : 95.58131720430107 \n",
      "Epoch : 18 , train_loss : 0.36606041477244095, train_acc : 96.35231316725978, val_loss : 0.36779096081692686, val_acc : 95.76612903225806 \n",
      "Epoch : 19 , train_loss : 0.34676531105703307, train_acc : 96.42459964412811, val_loss : 0.3499637605041586, val_acc : 95.66532258064517 \n",
      "Epoch : 20 , train_loss : 0.32936462229681185, train_acc : 96.43016014234875, val_loss : 0.3350706443350802, val_acc : 95.59811827956989 \n",
      "Epoch : 21 , train_loss : 0.31355289361867195, train_acc : 96.48020462633453, val_loss : 0.3192892686654163, val_acc : 95.81653225806451 \n",
      "Epoch : 22 , train_loss : 0.2990546111958731, train_acc : 96.52468861209964, val_loss : 0.30621331689819214, val_acc : 95.78293010752688 \n",
      "Epoch : 23 , train_loss : 0.2857575663149993, train_acc : 96.56361209964413, val_loss : 0.29411284112802116, val_acc : 95.81653225806451 \n",
      "Epoch : 24 , train_loss : 0.2735005469190693, train_acc : 96.64145907473309, val_loss : 0.2829561710998576, val_acc : 95.91733870967742 \n",
      "Epoch : 25 , train_loss : 0.2621232761713109, train_acc : 96.7248665480427, val_loss : 0.27249952974498914, val_acc : 95.96774193548387 \n",
      "Epoch : 26 , train_loss : 0.25164000727103697, train_acc : 96.73042704626334, val_loss : 0.26195636375616954, val_acc : 96.0013440860215 \n",
      "Epoch : 27 , train_loss : 0.24166156017483342, train_acc : 96.85831850533808, val_loss : 0.25212254431298986, val_acc : 96.15255376344086 \n",
      "Epoch : 28 , train_loss : 0.23252307260375854, train_acc : 96.88056049822065, val_loss : 0.24534513232528524, val_acc : 96.08534946236558 \n",
      "Epoch : 29 , train_loss : 0.22395554550814034, train_acc : 96.93616548042705, val_loss : 0.23676212740841732, val_acc : 96.06854838709677 \n",
      "Epoch : 30 , train_loss : 0.21602810537475708, train_acc : 96.95284697508897, val_loss : 0.22908346258824872, val_acc : 96.15255376344086 \n",
      "Epoch : 31 , train_loss : 0.20848861490492296, train_acc : 96.98620996441281, val_loss : 0.22578690962124898, val_acc : 96.03494623655914 \n",
      "Epoch : 32 , train_loss : 0.20134697403772023, train_acc : 97.09185943060498, val_loss : 0.2158826825118834, val_acc : 96.23655913978494 \n",
      "Epoch : 33 , train_loss : 0.19465694695817193, train_acc : 97.09185943060498, val_loss : 0.21001446984147512, val_acc : 96.33736559139786 \n",
      "Epoch : 34 , train_loss : 0.1884692687262844, train_acc : 97.13634341637011, val_loss : 0.20254000076042708, val_acc : 96.40456989247312 \n",
      "Epoch : 35 , train_loss : 0.1824994696522947, train_acc : 97.21419039145907, val_loss : 0.19769761446983583, val_acc : 96.3877688172043 \n",
      "Epoch : 36 , train_loss : 0.17673690754960017, train_acc : 97.29203736654804, val_loss : 0.1923578671550238, val_acc : 96.35416666666667 \n",
      "Epoch : 37 , train_loss : 0.17141157160662246, train_acc : 97.29759786476869, val_loss : 0.1881036264922029, val_acc : 96.43817204301075 \n",
      "Epoch : 38 , train_loss : 0.16649027237688518, train_acc : 97.33652135231317, val_loss : 0.18193225202060515, val_acc : 96.4885752688172 \n",
      "Epoch : 39 , train_loss : 0.16161710660228526, train_acc : 97.3810053380783, val_loss : 0.18071837362743193, val_acc : 96.47177419354838 \n",
      "Epoch : 40 , train_loss : 0.15702087501083828, train_acc : 97.4366103202847, val_loss : 0.17455450076890247, val_acc : 96.60618279569893 \n",
      "Epoch : 41 , train_loss : 0.15278384990963648, train_acc : 97.48665480427046, val_loss : 0.17132872527325024, val_acc : 96.58938172043011 \n",
      "Epoch : 42 , train_loss : 0.14867870480458506, train_acc : 97.52557829181495, val_loss : 0.16355796238427522, val_acc : 96.74059139784946 \n",
      "Epoch : 43 , train_loss : 0.144770398682971, train_acc : 97.57006227758008, val_loss : 0.16184736716170464, val_acc : 96.72379032258064 \n",
      "Epoch : 44 , train_loss : 0.141040721185691, train_acc : 97.59786476868328, val_loss : 0.15899195433944785, val_acc : 96.70698924731182 \n",
      "Epoch : 45 , train_loss : 0.13743961745627833, train_acc : 97.62566725978648, val_loss : 0.15693364292383194, val_acc : 96.65658602150538 \n",
      "Epoch : 46 , train_loss : 0.1340401135252464, train_acc : 97.66459074733096, val_loss : 0.15299900909585337, val_acc : 96.75739247311827 \n",
      "Epoch : 47 , train_loss : 0.13079900588853505, train_acc : 97.69795373665481, val_loss : 0.15036411399161945, val_acc : 96.79099462365592 \n",
      "Epoch : 48 , train_loss : 0.12756048386843602, train_acc : 97.75911921708185, val_loss : 0.14679157605735205, val_acc : 96.875 \n",
      "Epoch : 49 , train_loss : 0.12465091208758303, train_acc : 97.7924822064057, val_loss : 0.1452205170707036, val_acc : 96.89180107526882 \n",
      "Epoch : 50 , train_loss : 0.12191063963751776, train_acc : 97.82584519572954, val_loss : 0.1435322396216854, val_acc : 96.875 \n",
      "Epoch : 51 , train_loss : 0.11914003950633188, train_acc : 97.8480871886121, val_loss : 0.14010712496375524, val_acc : 96.95900537634408 \n",
      "Epoch : 52 , train_loss : 0.11658624731985276, train_acc : 97.8480871886121, val_loss : 0.13788162836784956, val_acc : 96.85819892473118 \n",
      "Epoch : 53 , train_loss : 0.11410734182044704, train_acc : 97.89257117437722, val_loss : 0.1344600534567269, val_acc : 97.07661290322581 \n",
      "Epoch : 54 , train_loss : 0.1117202542006333, train_acc : 97.90925266903915, val_loss : 0.13298054031466924, val_acc : 97.05981182795699 \n",
      "Epoch : 55 , train_loss : 0.10919787697626603, train_acc : 97.9314946619217, val_loss : 0.12498010398559672, val_acc : 97.21102150537635 \n",
      "Epoch : 56 , train_loss : 0.10725650539973028, train_acc : 97.96485765124555, val_loss : 0.12837366006707632, val_acc : 97.11021505376344 \n",
      "Epoch : 57 , train_loss : 0.10516676003133275, train_acc : 97.96485765124555, val_loss : 0.12112549219721107, val_acc : 97.27822580645162 \n",
      "Epoch : 58 , train_loss : 0.10306434882175032, train_acc : 97.98153914590748, val_loss : 0.12403588790086008, val_acc : 97.16061827956989 \n",
      "Epoch : 59 , train_loss : 0.10123319316695169, train_acc : 98.02046263345196, val_loss : 0.12236824171036802, val_acc : 97.22782258064517 \n",
      "Epoch : 60 , train_loss : 0.09928053846828029, train_acc : 98.04270462633453, val_loss : 0.11964606770103978, val_acc : 97.2614247311828 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 61 , train_loss : 0.09758567466695538, train_acc : 98.07050711743773, val_loss : 0.11960009197073598, val_acc : 97.19422043010752 \n",
      "Epoch : 62 , train_loss : 0.09570211300699312, train_acc : 98.08718861209964, val_loss : 0.11921687972962215, val_acc : 97.22782258064517 \n",
      "Epoch : 63 , train_loss : 0.09419816952477146, train_acc : 98.09830960854093, val_loss : 0.11530107335858447, val_acc : 97.32862903225806 \n",
      "Epoch : 64 , train_loss : 0.09261049669620405, train_acc : 98.12055160142349, val_loss : 0.11487543114250706, val_acc : 97.34543010752688 \n",
      "Epoch : 65 , train_loss : 0.09111614311876245, train_acc : 98.17059608540926, val_loss : 0.11283397730640186, val_acc : 97.41263440860214 \n",
      "Epoch : 66 , train_loss : 0.08940543435858662, train_acc : 98.19283807829181, val_loss : 0.11294782153701269, val_acc : 97.34543010752688 \n",
      "Epoch : 67 , train_loss : 0.08821831406276422, train_acc : 98.20395907473309, val_loss : 0.11183230126256584, val_acc : 97.34543010752688 \n",
      "Epoch : 68 , train_loss : 0.08667030064819971, train_acc : 98.24844306049822, val_loss : 0.1126126318529088, val_acc : 97.32862903225806 \n",
      "Epoch : 69 , train_loss : 0.08555683818417087, train_acc : 98.24844306049822, val_loss : 0.10884125066059892, val_acc : 97.37903225806451 \n",
      "Epoch : 70 , train_loss : 0.08424356821062726, train_acc : 98.24844306049822, val_loss : 0.10829778672546468, val_acc : 97.44623655913979 \n",
      "Epoch : 71 , train_loss : 0.08309855864936772, train_acc : 98.27624555160142, val_loss : 0.10712023087406672, val_acc : 97.53024193548387 \n",
      "Epoch : 72 , train_loss : 0.08196028608338264, train_acc : 98.29292704626334, val_loss : 0.1028287907842026, val_acc : 97.59744623655914 \n",
      "Epoch : 73 , train_loss : 0.0808189996647453, train_acc : 98.30404804270462, val_loss : 0.10346750999169965, val_acc : 97.54704301075269 \n",
      "Epoch : 74 , train_loss : 0.07976127225653769, train_acc : 98.32629003558719, val_loss : 0.10480888067714629, val_acc : 97.49663978494624 \n",
      "Epoch : 75 , train_loss : 0.07870563301937224, train_acc : 98.32072953736655, val_loss : 0.10052710907754078, val_acc : 97.63104838709677 \n",
      "Epoch : 76 , train_loss : 0.07773174768399937, train_acc : 98.34297153024912, val_loss : 0.10039451163542527, val_acc : 97.58064516129032 \n",
      "Epoch : 77 , train_loss : 0.07678400228641848, train_acc : 98.3540925266904, val_loss : 0.1019580590148126, val_acc : 97.46303763440861 \n",
      "Epoch : 78 , train_loss : 0.07579301906835778, train_acc : 98.37077402135232, val_loss : 0.10004325863975351, val_acc : 97.59744623655914 \n",
      "Epoch : 79 , train_loss : 0.07495000913368001, train_acc : 98.36521352313167, val_loss : 0.09713764855217549, val_acc : 97.64784946236558 \n",
      "Epoch : 80 , train_loss : 0.0740991899962421, train_acc : 98.37077402135232, val_loss : 0.09845383016652959, val_acc : 97.59744623655914 \n",
      "Epoch : 81 , train_loss : 0.07328092493779718, train_acc : 98.39857651245552, val_loss : 0.09436550476057555, val_acc : 97.76545698924731 \n",
      "Epoch : 82 , train_loss : 0.07250267059088178, train_acc : 98.39301601423487, val_loss : 0.09606966212071398, val_acc : 97.71505376344086 \n",
      "Epoch : 83 , train_loss : 0.07173035830073722, train_acc : 98.40413701067615, val_loss : 0.09376006559418734, val_acc : 97.7486559139785 \n",
      "Epoch : 84 , train_loss : 0.07099310663326568, train_acc : 98.39857651245552, val_loss : 0.0961314814906287, val_acc : 97.66465053763442 \n",
      "Epoch : 85 , train_loss : 0.07029533017678617, train_acc : 98.40413701067615, val_loss : 0.09177679051795314, val_acc : 97.81586021505376 \n",
      "Epoch : 86 , train_loss : 0.0695759293911614, train_acc : 98.4375, val_loss : 0.09105411676629897, val_acc : 97.83266129032258 \n",
      "Epoch : 87 , train_loss : 0.06895290833510113, train_acc : 98.44862099644128, val_loss : 0.09098356399404746, val_acc : 97.79905913978494 \n",
      "Epoch : 88 , train_loss : 0.06828194533829375, train_acc : 98.47642348754448, val_loss : 0.08949526387356943, val_acc : 97.84946236559139 \n",
      "Epoch : 89 , train_loss : 0.06763602704393058, train_acc : 98.45974199288256, val_loss : 0.08791515904088174, val_acc : 97.93346774193549 \n",
      "Epoch : 90 , train_loss : 0.06701325509843029, train_acc : 98.47642348754448, val_loss : 0.09034328046505169, val_acc : 97.81586021505376 \n",
      "Epoch : 91 , train_loss : 0.06637753886286686, train_acc : 98.47642348754448, val_loss : 0.08733612002544505, val_acc : 97.84946236559139 \n",
      "Epoch : 92 , train_loss : 0.06579817508701964, train_acc : 98.49866548042705, val_loss : 0.09011397338522378, val_acc : 97.78225806451613 \n",
      "Epoch : 93 , train_loss : 0.06520711844687573, train_acc : 98.5209074733096, val_loss : 0.08916349620908819, val_acc : 97.81586021505376 \n",
      "Epoch : 94 , train_loss : 0.06455861254731107, train_acc : 98.57651245551601, val_loss : 0.08823569535568196, val_acc : 97.76545698924731 \n",
      "Epoch : 95 , train_loss : 0.06417031839383878, train_acc : 98.55983096085409, val_loss : 0.0891075346178265, val_acc : 97.7486559139785 \n",
      "Epoch : 96 , train_loss : 0.06367236223350216, train_acc : 98.55983096085409, val_loss : 0.08706200399225758, val_acc : 97.78225806451613 \n",
      "Epoch : 97 , train_loss : 0.06322119206693885, train_acc : 98.57651245551601, val_loss : 0.0836837696292067, val_acc : 97.91666666666667 \n",
      "Epoch : 98 , train_loss : 0.06274457536041206, train_acc : 98.59319395017793, val_loss : 0.08775964609637696, val_acc : 97.86626344086021 \n",
      "Epoch : 99 , train_loss : 0.062278932338295456, train_acc : 98.6154359430605, val_loss : 0.08334582477247202, val_acc : 97.89986559139786 \n",
      "Epoch : 100 , train_loss : 0.06185480020277441, train_acc : 98.62099644128114, val_loss : 0.0831971633378216, val_acc : 97.88306451612904 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    hidden_state = None\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = AverageMeter()\n",
    "    train_accs = AverageMeter()\n",
    "    for idx, (images, target) in enumerate(train_loader):\n",
    "        #print(images.shape)\n",
    "        images = images.permute(1,0,2).cuda()\n",
    "        target = target.cuda()\n",
    "        images = images.type(torch.cuda.FloatTensor)\n",
    "        y_pred, hidden_state = model(images, hidden_state)\n",
    "        #print(\"y_pred\",y_pred)\n",
    "\n",
    "        stateful = False\n",
    "        if not stateful:\n",
    "            hidden_state = None\n",
    "        else:\n",
    "            h_0, c_0 = hidden_state\n",
    "            h_0.detach_(), c_0.detach_()\n",
    "            hidden_state = (h_0, c_0)\n",
    "\n",
    "        train_loss = criterion(y_pred, target)\n",
    "        #print(train_loss)\n",
    "        \n",
    "        train_losses.update(train_loss.item(), images.size(0)) \n",
    "        train_acc = Accuracy(y_pred, target)\n",
    "        train_accs.update(train_acc[0].item(), images.size(0))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        train_loss.backward()  # backward pass\n",
    "        optimizer.step()  # parameter update\n",
    "    #lr_scheduler.step(train_loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        hidden_state = None\n",
    "        \n",
    "        val_losses = AverageMeter()\n",
    "        val_accs = AverageMeter()\n",
    "        \n",
    "        for idx, (images, target) in enumerate(val_loader):\n",
    "            images = images.permute(1,0,2).cuda()\n",
    "            target = target.cuda()\n",
    "            images = images.type(torch.cuda.FloatTensor)\n",
    "\n",
    "            y_pred, hidden_state = model(images, hidden_state)\n",
    "            \n",
    "            val_loss = criterion(y_pred, target)\n",
    "            val_losses.update(val_loss.item(), images.size(0)) \n",
    "\n",
    "            val_acc = Accuracy(y_pred, target)\n",
    "            val_accs.update(val_acc[0].item(), images.size(0))\n",
    "            \n",
    "            stateful = True\n",
    "            if not stateful:\n",
    "                hidden_state = None\n",
    "            else:\n",
    "                h_0, c_0 = hidden_state\n",
    "                h_0.detach_(), c_0.detach_()\n",
    "                hidden_state = (h_0, c_0)\n",
    "    \n",
    "    print('Epoch : {} , train_loss : {}, train_acc : {}, val_loss : {}, val_acc : {} '.format(epoch+1, train_losses.avg, train_accs.avg, val_losses.avg, val_accs.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f7d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c6281e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
